AWSTemplateFormatVersion: "2010-09-09"
Transform: AWS::Serverless-2016-10-31
Description: Simple Glue job-based Transform

Parameters:
  pPipelineReference:
    Description: Workaround for CloudFormation resolve:ssm not updating on stack update (https://github.com/aws-cloudformation/cloudformation-coverage-roadmap/issues/844)
    Type: String
    Default: none
  pDeploymentInstance:
    Type: String
    Description: A string uniquely identifying this deployment in this AWS account
    Default: glue
  pDatasetDeploymentInstance:
    Type: String
    Description: The string uniquely identifying a sdlf-dataset deployment in this AWS account
    Default: "" # see below comments
  pPipelineExecutionHistoryDynamoTable:
    Type: String
    Description: Name of the Dynamo table storing pipeline execution data
    Default: "" # if not provided, pDatasetDeploymentInstance must be specified
  pManifestsDynamoTable:
    Type: String
    Description: Name of the Dynamo table storing pipeline execution data
    Default: "" # if not provided, pDatasetDeploymentInstance must be specified
  pGlueCrawler:
    Description: Glue crawler for the dataset
    Type: String
    Default: "" # if not provided, pDatasetDeploymentInstance must be specified
  pInfraKmsKey:
    Description: KMS key set as infra key for the dataset
    Type: String
    Default: "" # if not provided, pDatasetDeploymentInstance must be specified
  pEventBus:
    Description: EventBridge bus for the dataset
    Type: String
    Default: "" # if not provided, pDatasetDeploymentInstance must be specified
  pScheduleGroup:
    Description: EventBridge schedule group for the dataset
    Type: String
    Default: "" # if not provided, pDatasetDeploymentInstance must be specified
  pStorageDeploymentInstance:
    Type: String
    Description: The string uniquely identifying a sdlf-foundations deployment in this AWS account
    Default: "" # see below comments
  # pRawBucket:
  #   Description: Raw bucket
  #   Type: String
  #   Default: "" # if not provided, pStorageDeploymentInstance must be specified
  # pStageBucket:
  #   Description: Stage bucket
  #   Type: String
  #   Default: "" # if not provided, pStorageDeploymentInstance must be specified
  # pAnalyticsBucket:
  #   Description: Analytics bucket
  #   Type: String
  #   Default: "" # if not provided, pStorageDeploymentInstance must be specified
  pDataset:
    Description: The name of the dataset (all lowercase, no symbols or spaces)
    Type: String
    AllowedPattern: "[a-z0-9]{2,14}"
  pPipeline:
    Description: The name of the pipeline (all lowercase, no symbols or spaces)
    Type: String
    AllowedPattern: "[a-z0-9]*"
  pStageName:
    Description: Name of the stage (all lowercase, hyphen allowed, no other symbols or spaces)
    Type: String
    AllowedPattern: "[a-zA-Z0-9\\-]{1,12}"
  pStageEnabled:
    Description: Whether the stage is enabled or not
    Type: String
    Default: true
    AllowedValues: [true, false]
  pTriggerType:
    Description: Trigger type of the stage (event or schedule)
    Type: String
    Default: event
    AllowedValues: [event, schedule]
  pSchedule:
    Description: Cron expression when trigger type is schedule
    Type: String
    Default: "cron(*/5 * * * ? *)"
  pEventPattern:
    Description: Event pattern to match from previous stage
    Type: String
    Default: ""
  pCloudWatchLogsRetentionInDays:
    Description: The number of days log events are kept in CloudWatch Logs
    Type: Number
    Default: 30
    AllowedValues:
      [
        1,
        3,
        5,
        7,
        14,
        30,
        60,
        90,
        120,
        150,
        180,
        365,
        400,
        545,
        731,
        1827,
        3653,
      ]
  pEnableTracing:
    Description: Flag for whether XRay tracing is enabled
    Type: String
  pMaxItemsPerBatch:
    Description: Maximum number of items to process per batch - each Glue job execution will process that many items, if available
    Type: Number
    Default: 5
  pGlueJobName:
    Description: Glue job name
    Type: String
  pGlueNumberOfWorkers:
    Description: Number of workers assigned for the Glue job
    Type: Number
    Default: 10
    MinValue: 2
    MaxValue: 100
  pGlueWorkerType:
    Description: Worker type to use for the Glue job
    Type: String
    Default: G.1X
    AllowedValues: [G.1X, G.2X, G.4X, G.8X, G.025X]
  pGlueArguments:
    Description: Glue job arguments (JSON)
    Type: String
  # the ideal would be to fetch ssm:/SDLF/VPC/Enabled and not ask the user to set this variable to true manually.
  # however between AWS::SSM::Parameter::Value<String> not working in CloudFormation modules,
  # Fn::ImportValue not being accepted in CloudFormation modules template fragments,
  # {{resolve:}} being evaluated later than the Conditions block, options are limited.
  pEnableVpc:
    Description: Deploy SDLF resources in a VPC
    Type: String
    Default: false
  # pVpcSecurityGroupIds and pVpcSubnetIds are passed explicitly (unlike in sdlf-cicd/template-cicd-sdlf-repositories.yaml for example)
  # due to Fn::ImportValue not being accepted in CloudFormation modules template fragments
  pVpcSecurityGroupIds:
    Description: VPC Security Groups Ids
    Type: String
    Default: ""
  pVpcSubnetIds:
    Description: VPC Subnet Ids
    Type: String
    Default: ""

Conditions:
  EnableTracing: !Equals [!Ref pEnableTracing, "true"]
  FetchFromDatasetSsm: !Not [!Equals [!Ref pDatasetDeploymentInstance, ""]]
  RunInVpc: !Equals [!Ref pEnableVpc, true]

Globals:
  Function:
    Runtime: python3.12
    Handler: lambda_function.lambda_handler
    Layers:
      - "{{resolve:ssm:/SDLF/Lambda/LatestDatalakeLibraryLayer}}"
    Environment:
      Variables:
        DATASET: !Ref pDataset
        PIPELINE: !Ref pPipeline
        PIPELINE_STAGE: !Ref pStageName
        DEPLOYMENT_INSTANCE: !Ref pDeploymentInstance
        STORAGE_DEPLOYMENT_INSTANCE: !Ref pStorageDeploymentInstance
        DATASET_DEPLOYMENT_INSTANCE: !Ref pDatasetDeploymentInstance
        PIPELINE_EXECUTION_HISTORY_DYNAMO_TABLE: !Ref pPipelineExecutionHistoryDynamoTable
        MANIFESTS_DYNAMO_TABLE: !Ref pManifestsDynamoTable
    KmsKeyArn: !If [FetchFromDatasetSsm, !Sub "{{resolve:ssm:/sdlf/dataset/rKMSInfraKey/${pDatasetDeploymentInstance}}}", !Ref pInfraKmsKey]
    VpcConfig: !If
      - RunInVpc
      - SecurityGroupIds: !Split [",", !Ref pVpcSecurityGroupIds]
        SubnetIds: !Split [",", !Ref pVpcSubnetIds]
      - !Ref "AWS::NoValue"


Resources:
  rPipelineInterface:
    Type: awslabs::sdlf::pipeline::MODULE
    Properties:
      pPipelineReference: !Ref pPipelineReference
      pDeploymentInstance: !Ref pDeploymentInstance
      pDatasetDeploymentInstance: !Ref pDatasetDeploymentInstance
      pInfraKmsKey: !Ref pInfraKmsKey
      pEventBus: !Ref pEventBus
      pScheduleGroup: !Ref pScheduleGroup
      pDataset: !Ref pDataset
      pPipelineName: !Ref pPipeline
      pStageName: !Ref pStageName
      pStageEnabled: !Ref pStageEnabled
      pTriggerType: !Ref pTriggerType
      pSchedule: !Ref pSchedule
      pEventPattern: !Ref pEventPattern
      pLambdaRoutingStep: !GetAtt rLambdaRoutingStep.Arn

  ######## IAM #########
  rLambdaCommonPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      Path: !Sub /sdlf-${pDataset}/
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Action:
              - logs:CreateLogGroup
              - logs:CreateLogStream
              - logs:PutLogEvents
            Resource:
              - !Sub arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/sdlf-${pDataset}-${pPipeline}-*
          - Effect: Allow
            Action:
              - ssm:GetParameter
              - ssm:GetParameters
            Resource: !Sub arn:${AWS::Partition}:ssm:${AWS::Region}:${AWS::AccountId}:parameter/sdlf/*
          - Effect: Allow
            Action:
              - dynamodb:BatchGetItem
              - dynamodb:BatchWriteItem
              - dynamodb:DeleteItem
              - dynamodb:DescribeTable
              - dynamodb:GetItem
              - dynamodb:GetRecords
              - dynamodb:PutItem
              - dynamodb:Query
              - dynamodb:Scan
              - dynamodb:UpdateItem
            Resource:
              - !Sub arn:${AWS::Partition}:dynamodb:${AWS::Region}:${AWS::AccountId}:table/sdlf-*
          - Effect: Allow
            Action:
              - kms:CreateGrant
              - kms:Decrypt
              - kms:DescribeKey
              - kms:Encrypt
              - kms:GenerateDataKey*
              - kms:ReEncrypt*
            Resource: 
              - !If [FetchFromDatasetSsm, !Sub "{{resolve:ssm:/sdlf/dataset/rKMSInfraKey/${pDatasetDeploymentInstance}}}", !Ref pInfraKmsKey]

  # Routing Role
  rRoleLambdaExecutionRoutingStep:
    Type: AWS::IAM::Role
    Properties:
      Path: !Sub /sdlf-${pDataset}/
      # PermissionsBoundary: !Sub "{{resolve:ssm:/SDLF/IAM/${pDataset}/TeamPermissionsBoundary}}"
      ManagedPolicyArns:
        - !Ref rLambdaCommonPolicy
        - !If
          - RunInVpc
          - !Sub arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole
          - !Ref "AWS::NoValue"
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: !Sub sdlf-${pDataset}-${pPipeline}-${pStageName}-routing
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - states:StartExecution
                Resource:
                  - !Ref rStateMachine
              - Effect: Allow
                Action:
                  - sqs:DeleteMessage
                  - sqs:GetQueueAttributes
                  - sqs:GetQueueUrl
                  - sqs:ListQueues
                  - sqs:ListDeadLetterSourceQueues
                  - sqs:ListQueueTags
                  - sqs:ReceiveMessage
                  - sqs:SendMessage
                Resource:
                  - !Sub arn:${AWS::Partition}:sqs:${AWS::Region}:${AWS::AccountId}:sdlf-${pDataset}-${pPipeline}-queue-*
                  - !Sub arn:${AWS::Partition}:sqs:${AWS::Region}:${AWS::AccountId}:sdlf-${pDataset}-${pPipeline}-dlq-*

  # Metadata Step Role (fetch metadata, update pipeline execution history...)
  rRoleLambdaExecutionMetadataStep:
    Type: AWS::IAM::Role
    Properties:
      Path: !Sub /sdlf-${pDataset}/
      # PermissionsBoundary: !Sub "{{resolve:ssm:/SDLF/IAM/${pDataset}/TeamPermissionsBoundary}}"
      ManagedPolicyArns:
        - !Ref rLambdaCommonPolicy
        - !If
          - RunInVpc
          - !Sub arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole
          - !Ref "AWS::NoValue"
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole

  # Error Handling Lambda Role
  rRoleLambdaExecutionErrorStep:
    Type: AWS::IAM::Role
    Properties:
      Path: !Sub /sdlf-${pDataset}/
      # PermissionsBoundary: !Sub "{{resolve:ssm:/SDLF/IAM/${pDataset}/TeamPermissionsBoundary}}"
      ManagedPolicyArns:
        - !Ref rLambdaCommonPolicy
        - !If
          - RunInVpc
          - !Sub arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole
          - !Ref "AWS::NoValue"
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: !Sub sdlf-${pDataset}-${pPipeline}-${pStageName}-error
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - sqs:DeleteMessage
                  - sqs:GetQueueAttributes
                  - sqs:GetQueueUrl
                  - sqs:ListQueues
                  - sqs:ListDeadLetterSourceQueues
                  - sqs:ListQueueTags
                  - sqs:ReceiveMessage
                  - sqs:SendMessage
                Resource:
                  - !Sub arn:${AWS::Partition}:sqs:${AWS::Region}:${AWS::AccountId}:sdlf-${pDataset}-${pPipeline}-dlq-*

  ######## LAMBDA FUNCTIONS #########
  rLambdaRoutingStep:
    Type: AWS::Serverless::Function
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W58
            reason: Permissions to write CloudWatch Logs are granted by rLambdaCommonPolicy
    Properties:
      CodeUri: ./lambda/routing/src
      FunctionName: !Sub sdlf-${pDataset}-${pPipeline}-${pStageName}-routing
      Description: Checks if items are to be processed and route them to state machine
      Environment:
        Variables:
          STAGE_TRANSFORM: ""
      MemorySize: 192
      Timeout: 60
      Role: !GetAtt rRoleLambdaExecutionRoutingStep.Arn

  rLambdaRedriveStep:
    Type: AWS::Serverless::Function
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W58
            reason: Permissions to write CloudWatch Logs are granted by rLambdaCommonPolicy
    Properties:
      CodeUri: ./lambda/redrive/src
      FunctionName: !Sub sdlf-${pDataset}-${pPipeline}-${pStageName}-redrive
      Description: Redrives Failed messages to the routing queue
      MemorySize: 192
      Timeout: 300
      Role: !GetAtt rRoleLambdaExecutionRoutingStep.Arn

  rLambdaPostMetadataStep:
    Type: AWS::Serverless::Function
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W58
            reason: Permissions to write CloudWatch Logs are granted by rLambdaCommonPolicy
    Properties:
      CodeUri: ./lambda/postupdate-metadata/src
      FunctionName: !Sub sdlf-${pDataset}-${pPipeline}-${pStageName}-postupdate
      Description: Post-Update the metadata in the DynamoDB Catalog table
      MemorySize: 192
      Timeout: 300
      Role: !GetAtt rRoleLambdaExecutionMetadataStep.Arn

  rLambdaErrorStep:
    Type: AWS::Serverless::Function
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W58
            reason: Permissions to write CloudWatch Logs are granted by rLambdaCommonPolicy
    Properties:
      CodeUri: ./lambda/error/src
      FunctionName: !Sub sdlf-${pDataset}-${pPipeline}-${pStageName}-error
      Description: Fallback lambda to handle messages which failed processing
      MemorySize: 192
      Timeout: 300
      Role: !GetAtt rRoleLambdaExecutionErrorStep.Arn

  ######## CLOUDWATCH #########
  rRoutingLambdaSsm:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub /sdlf/pipeline/rLambdaRoutingStep/${pDeploymentInstance}
      Type: String
      Value: !GetAtt rLambdaRoutingStep.Arn
      Description: !Sub "ARN of the ${pStageName} ${pDataset} ${pPipeline} Routing Lambda" # TODO

  rLambdaRoutingStepLogGroup:
    Type: AWS::Logs::LogGroup
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      LogGroupName: !Sub /aws/lambda/${rLambdaRoutingStep}
      RetentionInDays: !Ref pCloudWatchLogsRetentionInDays
      KmsKeyId: !If [FetchFromDatasetSsm, !Sub "{{resolve:ssm:/sdlf/dataset/rKMSInfraKey/${pDatasetDeploymentInstance}}}", !Ref pInfraKmsKey]

  rLambdaRedriveStepLogGroup:
    Type: AWS::Logs::LogGroup
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      LogGroupName: !Sub /aws/lambda/${rLambdaRedriveStep}
      RetentionInDays: !Ref pCloudWatchLogsRetentionInDays
      KmsKeyId: !If [FetchFromDatasetSsm, !Sub "{{resolve:ssm:/sdlf/dataset/rKMSInfraKey/${pDatasetDeploymentInstance}}}", !Ref pInfraKmsKey]

  rLambdaPostMetadataStepLogGroup:
    Type: AWS::Logs::LogGroup
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      LogGroupName: !Sub /aws/lambda/${rLambdaPostMetadataStep}
      RetentionInDays: !Ref pCloudWatchLogsRetentionInDays
      KmsKeyId: !If [FetchFromDatasetSsm, !Sub "{{resolve:ssm:/sdlf/dataset/rKMSInfraKey/${pDatasetDeploymentInstance}}}", !Ref pInfraKmsKey]

  rLambdaErrorStepLogGroup:
    Type: AWS::Logs::LogGroup
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      LogGroupName: !Sub /aws/lambda/${rLambdaErrorStep}
      RetentionInDays: !Ref pCloudWatchLogsRetentionInDays
      KmsKeyId: !If [FetchFromDatasetSsm, !Sub "{{resolve:ssm:/sdlf/dataset/rKMSInfraKey/${pDatasetDeploymentInstance}}}", !Ref pInfraKmsKey]

  ######## STATE MACHINE #########
  rStatesExecutionRole:
    Type: AWS::IAM::Role
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W11
            reason: The actions with "*" are all ones that do not have resource limitations associated with them
    Properties:
      Path: !Sub /sdlf-${pDataset}/
      # PermissionsBoundary: !Sub "{{resolve:ssm:/SDLF/IAM/${pDataset}/TeamPermissionsBoundary}}"
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - !Sub states.${AWS::Region}.amazonaws.com
            Action: sts:AssumeRole
            Condition:
              StringEquals:
                "aws:SourceAccount": !Sub ${AWS::AccountId}
      Policies:
        - PolicyName: !Sub sdlf-${pDataset}-${pPipeline}-${pStageName}-sm
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - lambda:InvokeFunction
                Resource: !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:${AWS::AccountId}:function:sdlf-${pDataset}-${pPipeline}-*
              - Effect: Allow
                Action:
                  - glue:StartJobRun
                  - glue:GetJobRun
                  - glue:GetJobRuns
                  - glue:BatchStopJobRun
                Resource: !Sub arn:${AWS::Partition}:glue:${AWS::Region}:${AWS::AccountId}:job/sdlf-${pDataset}-*
              - Effect: Allow
                Action:
                  - glue:StartCrawler
                  - glue:GetCrawler
                Resource: !Sub arn:${AWS::Partition}:glue:${AWS::Region}:${AWS::AccountId}:crawler/sdlf-${pDataset}-*
              - Effect: Allow
                Action:
                  - xray:PutTraceSegments # W11 exception
                  - xray:PutTelemetryRecords # W11 exception
                  - xray:GetSamplingRules # W11 exception
                  - xray:GetSamplingTargets # W11 exception
                Resource: "*"

  rStatesExecutionRoleMap:
    Type: AWS::IAM::RolePolicy
    Properties:
      PolicyName: sfn-map
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Action:
              - states:StartExecution
              - states:DescribeExecution
              - states:StopExecution
            Resource:
              - !Ref rStateMachine
              - !Sub arn:${AWS::Partition}:states:${AWS::Region}:${AWS::AccountId}:execution:${rStateMachine.Name}:*
      RoleName: !Ref rStatesExecutionRole

  rStateMachine:
    Type: AWS::Serverless::StateMachine
    Properties:
      Name: !Sub sdlf-${pDataset}-${pPipeline}-${pStageName}-sm
      DefinitionUri: ./state-machine/stage-glue.asl.json
      DefinitionSubstitutions:
        lPostMetadata: !GetAtt rLambdaPostMetadataStep.Arn
        lError: !GetAtt rLambdaErrorStep.Arn
        lMaxItemsPerBatch: !Ref pMaxItemsPerBatch
        lTransform: !Ref pGlueJobName
        lWorkerType: !Ref pGlueWorkerType
        lNumberOfWorkers: !Ref pGlueNumberOfWorkers
        lGlueArguments: !Ref pGlueArguments
        # lArguments:
        lCrawlerName: !If [FetchFromDatasetSsm, !Sub "{{resolve:ssm:/sdlf/dataset/rStageGlueCrawler/${pDatasetDeploymentInstance}}}", !Ref pGlueCrawler]
        lWaitTime: 75
      Role: !GetAtt rStatesExecutionRole.Arn
      Tracing:
        Enabled: !If [EnableTracing, true, false]

  rStateMachineSsm:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub /sdlf/pipeline/rStateMachine/${pDeploymentInstance}
      Type: String
      Value: !Ref rStateMachine
      Description: !Sub "ARN of the ${pStageName} ${pDataset} ${pPipeline} State Machine" # TODO

Outputs:
  oPipelineReference:
    Description: CodePipeline reference this stack has been deployed with
    Value: !Ref pPipelineReference
